# Face-Recognition
基于深度学习的人脸识别算法
1. 人脸识别原理
1.1 原理分析
人脸对齐采用的是YOLOv5-Face深度学习算法，YOLO5Face是深圳神目科技&LinkSprite Technologies开源的一个新SOTA的人脸检测器（带关键点）。YOLOv5Face针对人脸检测的对YOLOv5进行了再设计和修改，考虑到大人脸、小人脸、Landmark监督等不同的复杂性和应用。并且在 YOLOv5 网络中加了一个预测5个关键点 regression head，采用Wing loss进行作为损失函数。

1.2 特征提取
特征提取采用SphereFace深度学习算法，SphereFace提出了归一化权值（normalize weights and zero biases）和角度间距（angular margin），基于这2个点，对传统的softmax 进行了改进，从而实现了最大类内距离小于最小类间距离的识别标准。改进后的A-Softmax loss（Angular Softmax loss）使CNN（CNN使用ResNet种的残差单元）能够学习角度识别特征，引人了角度间隔m，以使人脸特征的最大类内距离要小于最小类间距离，使学习的特征将更具有判别力。最终实现将对齐后的人脸图片最为输入，输出shape为（1，512）的特征向量。

1.3 人脸比对
人脸比对采用余弦相似度的方式对比两个人脸特征之间的相似性，并设定一定的阈值，当两个人脸相似度高于阈值则认为是同一个人，否则不是同一个人。余弦相似度计算的是两向量在高维度空间中的夹角余弦值。夹角越小,余弦相似度越大:角度越大,余弦相似度越小(最小值为0,最大值为1),其值与向量的模长(即图片整体的亮度)无关,而取决于各个维度上分量的大小差异(即图片上各点间的灰度值差异)。因此图片的整体明暗程度对余弦相似度的影响不大,而各点间的明暗变化对余弦相似度的影响很大,这就很好地屏蔽了拍照时环境的明暗程度对人脸识别的影响。并且,由于余弦相似度的值介于0到1之间,可直接用于表示两张人脸图片的相似度,无需进一步转化。

2. 数据集
基于Q学友采集的人脸数据集进行研发，为了排除异常人脸数据的干扰，预先对人脸数据集进行数据处理。针对人脸数据集，剔除了拍摄不清晰或拍摄面部不全的人脸数据。最终获得共26,351条语音数据，按照70%、15%、15%划分训练集、验证集、测试集，具体划分：训练集：18,448、验证集：3,953、测试集：3,953。

3. 实验环境
本项目所有实验均在Ubuntu 18.04操作系统下完成和实现，使用了基于Python3.7的Pytorch深度学习框架，英伟达显卡驱动版本为Driver Version: 440.82，CUDA版本为10.1。下面给出了利用该算法进行推理时依赖的第三方Python库。

Ubuntu: 18.04 lts
Python 3.7.8
Pytorch 1.6.0
NVIDIA GPU + CUDA_10.0 CuDNN_7.5
4. 实验结果
场景1：根统计Q学友人脸数据集，数据集中共有1000个不同的人脸图像，每个人的0号图片一般为为身份证或证件照图片，1号图片为登录时采集的图片，场景1需要对比注册时证件照或身份证图片0与登录时采集的图片1是否为同一个人。 采用上述的人脸识别原理及方法对场景1进行测试，首次构建测试文件，测试文件如下图所示，需要验证图片1和图片2是否为同一个人，保证需要验证的图片一个是身份证图片，一个是登录时采集的图片。测试文件共有2000行均为随机选取，其中1000行为同一人的图片0和1，相应的标签为1，1000行不同人的图片0和图片1，相应的标签为0。 最终的测试精度为87.58%，阈值为0.4010。 场景2：验证登录时采集的图片与学习过程中随机采集的图片是否为同一个人，在数据集中图片1为登录时采集的图片，从1之后的图片为学习过程中采集的图片。因此在构建测试文件时，保证其中一个图片为登录时的图片，另一个图片为学习过程中采集的图片。测试文件共有2000行均为随机选取，其中1000行为同一人的图片0和1，相应的标签为1，1000行不同人的图片0和图片1，相应的标签为0。 最终的测试精度为95.85%，阈值为0.4760。

5. 训练与测试
Train
python train.py
Test
lfw.tgz to lfw.zip
# qxy.tgz to qxy.zip
tar zxf qxy.tgz; cd qxy; zip -r ../qxy.zip *; cd ..

# lfw evaluation
python qxy_eval.py --model model/sphere_qxy200.pth
