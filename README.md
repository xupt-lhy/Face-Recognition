# Face-Recognition
基于深度学习的人脸识别算法
1. 人脸识别原理
1.1 人脸自动定位
针对人脸检测问题，对YOLOv5进行再设计和修改，考虑到大、小人脸、Landmark监督等不同的复杂性和应用，基于YOLOv5-face算法研发人脸识别。在 YOLOv5 网络中加入5个关键点 regression head预测模块，采用Wing loss进行作为损失函数。YOLOv5-face设计了不同模型尺寸的检测器，从大型模型到中型模型，再到超小模型，以满足不同应用中的需要。实现了一个基于ShuffleNetV2的backbone，为移动设备提供了更快的速度和最先进的性能。

1.2 特征提取
在人脸定位之后，需要提取人脸特征进行比对，为便于在移动端部署项目，我们选取高效的轻量级模型ShuffleNet作为主干网络。ShuffleNet是旷视科技最近提出的一种计算高效的CNN模型，其和MobileNet和SqueezeNet等一样主要是想应用在移动端。所以，ShuffleNet的设计目标也是如何利用有限的计算资源来达到最好的模型精度，这需要很好地在速度和精度之间做平衡。ShuffleNet的核心是采用了两种操作：pointwise group convolution和channel shuffle，这在保持精度的同时大大降低了模型的计算量。目前移动端CNN模型主要设计思路主要是两个方面：模型结构设计和模型压缩。ShuffleNet和MobileNet一样属于前者，都是通过设计更高效的网络结构来实现模型变小和变快，而不是对一个训练好的大模型做压缩或者迁移。在本项目中，我们采用ShuffleNet作为主干特征提取网络，并使用Pytorch来实现ShuffleNet网络。

1.3 人脸比对
当涉及到人脸识别项目时，人脸对齐是一个非常重要的步骤。因为在不同的图像中，人脸的朝向、姿态和光照条件都可能会有所不同，这会导致人脸特征的变化。而人脸对齐的目的就是将不同的人脸图像转换成一个标准的姿态、朝向和大小，以便于后续的人脸检测、识别或比对。在本项目中，人脸对齐指的是在人脸检测之后，将一张人脸图像的所有关键点调整为一个标准位置，用来进行人脸特征提取和比对。为了提升人脸识别项目的精确度，我们采用如下步骤进行人脸对齐：
（1）提取关键点：在检测到人脸后，需要使用关键点检测算法提取人脸图像的关键点。这些关键点通常包括眼睛、鼻子、嘴巴等特征点，我们采用OpenCV中的仿射变换作为关键点检测算法。
（2）	计算变换矩阵：通过将人脸的关键点映射到一个标准的人脸模型，可以计算出变换矩阵，用于将人脸图像对齐到标准位置。
（3）对齐人脸：最后一步是将人脸图像根据计算出的变换矩阵进行对齐，使得人脸图像的关键点处于标准位置。
通过对齐人脸，可以减少不同人脸图像之间的差异，提高后续的人脸识别或比对的准确率。 

2. 数据集
基于Q学友采集的人脸数据集进行研发，为了排除异常人脸数据的干扰，预先对人脸数据集进行数据处理。针对人脸数据集，剔除了拍摄不清晰或拍摄面部不全的人脸数据。最终获得共26,351条语音数据，按照70%、15%、15%划分训练集、验证集、测试集，具体划分：训练集：18,448、验证集：3,953、测试集：3,953。

3. 实验环境
本项目所有实验均在Ubuntu 18.04操作系统下完成和实现，使用了基于Python3.7的Pytorch深度学习框架，英伟达显卡驱动版本为Driver Version: 440.82，CUDA版本为10.1。下面给出了利用该算法进行推理时依赖的第三方Python库。

Ubuntu: 18.04 lts
Python 3.7.8
Pytorch 1.6.0
NVIDIA GPU + CUDA_10.0 CuDNN_7.5
4. 实验结果
场景1：根统计Q学友人脸数据集，数据集中共有1000个不同的人脸图像，每个人的0号图片一般为为身份证或证件照图片，1号图片为登录时采集的图片，场景1需要对比注册时证件照或身份证图片0与登录时采集的图片1是否为同一个人。 采用上述的人脸识别原理及方法对场景1进行测试，首次构建测试文件，测试文件如下图所示，需要验证图片1和图片2是否为同一个人，保证需要验证的图片一个是身份证图片，一个是登录时采集的图片。测试文件共有2000行均为随机选取，其中1000行为同一人的图片0和1，相应的标签为1，1000行不同人的图片0和图片1，相应的标签为0。 最终的测试精度为87.58%，阈值为0.4010。 场景2：验证登录时采集的图片与学习过程中随机采集的图片是否为同一个人，在数据集中图片1为登录时采集的图片，从1之后的图片为学习过程中采集的图片。因此在构建测试文件时，保证其中一个图片为登录时的图片，另一个图片为学习过程中采集的图片。测试文件共有2000行均为随机选取，其中1000行为同一人的图片0和1，相应的标签为1，1000行不同人的图片0和图片1，相应的标签为0。 最终的测试精度为95.85%，阈值为0.4760。


